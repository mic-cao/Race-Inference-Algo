---
title: "Race Prediction"
output:
  word_document: default
  pdf_document: default
  html_document: default
date: "2024-02-18"
---

```{r setup, include=FALSE, message=F}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(dplyr)
library(vroom)
library(foreach)
library(doParallel)
library(purrr)
library(pROC)
library(openxlsx)
```

```{r, message=F}
start <- proc.time()
path <- file.path('S:', 'CR4230', 'Projects', 
                  'Project Collaboration wx233_CR4230')
dat <- vroom(#n_max = 10000000,
             file.path(path, '1940_census_cleaned.parquet'))
dat <- as.data.table(dat)
print(proc.time()-start)
```

```{r}
round(colMeans(is.na(dat)), 4)
colSums(is.na(dat))
```
```{r}
dat <- dat[!is.na(dat$STATEFIP)]
dat <- dat[!is.na(dat$RACE)]
dat <- dat[RACE!="Non-Hispanic NA"]
dat$STATEFIP <- tolower(dat$STATEFIP)
dat$NAMEFRST <- tolower(dat$NAMEFRST)
dat$NAMELAST <- tolower(dat$NAMELAST)
```

Uncomment this to run white/nonwhite (CAUTION!!!)
```{r}
# sub_path <- "five races/"
# sub_path <- "two races (w-nw)/"
# dat$RACE <- ifelse(dat$RACE=="Non-Hispanic White", "White", "Non-White")
sub_path <- "two races (b-nb)/"
dat$RACE <- ifelse(dat$RACE=="Non-Hispanic Black", "Black", "Non-Black")
```

Add region mapping to census data
```{r}
dict_region <- read.csv("dict_region.csv")
dat$REGION <- dict_region$label[match(dat$STATEFIP, dict_region$value)]
```

Condense dataset (count for each unique first-last-state-race combination)
```{r}
nrow(dat)
dat_new <- dat[, .N, by = .(NAMEFRST, NAMELAST, STATEFIP, RACE, REGION)]
nrow(dat_new)
dat_new <- dat_new[complete.cases(dat_new)]
nrow(dat_new)
# rm(dat)
```

```{r}
loan_card <- readRDS("card_data_formichael_2024_04_24.rds")
loan_card <- as.data.table(loan_card)
names(loan_card)[names(loan_card)=="spouse_first"] <- "spouse"
nrow(loan_card)
round(colMeans(is.na(loan_card)), 4)
colSums(is.na(loan_card))
```

```{r}
table(loan_card$state_abr)
length(unique(loan_card$state_name))
```

For now, we will only work with states that exist in our census data. 
```{r}
states <- unique(dat_new$STATEFIP)
nrow(loan_card)
loan_card <- loan_card[loan_card$state_name %in% states,]
nrow(loan_card)
```

Adding further cleaning - 4/16/24
1) change all 1-letter first/spouse names to NA
2) remove duplicate records
```{r}
loan_card$first <- ifelse(nchar(loan_card$first) == 1, NA, loan_card$first)
loan_card$spouse <- ifelse(nchar(loan_card$spouse) == 1, NA, loan_card$spouse)

loan_card <- unique(loan_card) # dedup
nrow(loan_card)

file_name <- loan_card$file
loan_card <- loan_card[, c("first","last","spouse","state_name")]
nrow(unique(loan_card))
```


```{r}
race_tab <- tapply(dat_new$N, dat_new$RACE, sum)
race_tab
round(prop.table(race_tab),4)
```

Algorithm 1: BISG (with first name)  
P(R_i=r|S_i=s, F_i=f, G_i=g) =  
  P(G_i=g|R_i=r)P(R_i=r|S_i=s)P(F_i=f|R_i=r)/sum(P(G_i=g|R_i=r)P(R_i=r|S_i=s)P(F_i=f|R_i=r))  

relaxation rules (used if BISG gives NA or top two racial categories are equal)  
1) use spouse first name, rerun algorithm  
2) if still NA or tie, or spouse is NA, relax first name, and run BISG (only last name)  
3) if still NA or tie, keep it as is
```{r}
races <- unique(dat_new$RACE)
race_tab <- tapply(dat_new$N, dat_new$RACE, sum)[races]
dat_state <- dat_new[, .(N=sum(N)), by = .(STATEFIP, RACE)]
dat_region <- dat_new[, .(N=sum(N)), by = .(REGION, RACE)]
dat_last <- dat_new[, .(N=sum(N)), by = .(NAMELAST, RACE)]
dat_frst <- dat_new[, .(N=sum(N)), by = .(NAMEFRST, RACE)]
ln_tab <- tapply(dat_last$N, dat_last$NAMELAST, sum)
fn_tab <- tapply(dat_frst$N, dat_frst$NAMEFRST, sum)
```
```{r}
predict_race <- function(first, last, spouse, state)
{
  race_prob <- rep(NA, length(races))
  step <- 0
  d2 <- ln_tab[last]
  if (is.na(d2)||d2==0) {return(c(race_prob,step))}
  
  if (!is.na(first))
  {
    for (i in 1:length(races))
    {
      d1 <- race_tab[i]
      p1 <- dat_state[RACE==races[i]&STATEFIP==state, sum(N)]/d1
      p2 <- dat_last[RACE==races[i]&NAMELAST==last, sum(N)]/d2
      p3 <-  dat_frst[RACE==races[i]&NAMEFRST==first, sum(N)]/d1
      # print(c(p1,p2,p3))
      race_prob[i] <- p1*p2*p3
    }
    race_prob <- round(race_prob/sum(race_prob),4)
  }
  if (!anyNA(race_prob)) {step <- 1; return(c(race_prob,step))}
  
  # relax 1: using spouse
  if (!is.na(spouse))
  {
    for (i in 1:length(races))
    {
      d1 <- race_tab[i]
      p1 <- dat_state[RACE==races[i]&STATEFIP==state, sum(N)]/d1
      p2 <- dat_last[RACE==races[i]&NAMELAST==last, sum(N)]/d2
      p3 <- dat_frst[RACE==races[i]&NAMEFRST==spouse, sum(N)]/d1
      race_prob[i] <- p1*p2*p3
    }
    race_prob <- round(race_prob/sum(race_prob),4)
  }
  if (!anyNA(race_prob)) {step <- 2; return(c(race_prob,step))}
  
  # relax 2: drop first name (BISG - no F)
  for (i in 1:length(races))
  {
    p1 <- dat_state[RACE==races[i]&STATEFIP==state, sum(N)]/race_tab[i]
    p2 <- dat_last[RACE==races[i]&NAMELAST==last, sum(N)]/d2
    race_prob[i] <- p1*p2
  }
  race_prob <- round(race_prob/sum(race_prob),4)
  if (!anyNA(race_prob)) {step <- 3; return(c(race_prob,step))}
  
  # relax 3: region + last name
  # region <- dict_region$label[dict_region$value==state]
  # for (i in 1:length(races))
  # {
  #   p1 <- dat_region[RACE==races[i]&REGION==region, sum(N)]/race_tab[i]
  #   p2 <- dat_last[RACE==races[i]&NAMELAST==last, sum(N)]/d2
  #   race_prob[i] <- p1*p2
  # }
  # race_prob <- round(race_prob/sum(race_prob),4)
  # if (!anyNA(race_prob)) {step <- 4; return(c(race_prob,step))}
  # 
  # # relax 4: last name (no g)
  # for (i in 1:length(races))
  # {
  #   race_prob[i] <- dat_last[RACE==races[i]&NAMELAST==last, sum(N)]/d2
  # }
  # race_prob <- round(race_prob/sum(race_prob),4)
  # if (!anyNA(race_prob)) {step <- 5; return(c(race_prob,step))}
  return(c(race_prob,step))
}
```


```{r}
dat_new[NAMEFRST=="mary"&NAMELAST=="thomas"&STATEFIP=="new york",]
predict_race("mary", "thomas", NA, "new york")
```

```{r}
dat_new[NAMEFRST=="james"&NAMELAST=="wong"&STATEFIP=="new york",]
predict_race("james", "wong", NA, "new york")
dat_new[NAMEFRST=="james"&NAMELAST=="wong"&STATEFIP=="new jersey",]
predict_race("james", "wong", NA, "new jersey")
dat_new[NAMEFRST=="john"&NAMELAST=="wang"&STATEFIP=="new york",]
predict_race("john", "wang", NA, "new york") 
```
The algorithm works as intended in both cases, but this reflects a potential accuracy issue in the census data. For example, as per the census, there are more White 'John Wang's in the US than Asian ones.  

In the second case of James Wong from NJ, it exposes another drawback of BISG (with F); although there are more Asian people named James Wong in the US, the algorithm still predicts it to be more likely white, since there are no one named James Wong from NJ (despite dozens across the US).   

This issue does not exist if we implemented regular BISG (without first name). In fact, with BISG, considering only the last name Wong, it still over predicts 'Asian', albeit with smaller difference.
predict_race("James", "Wong", NA, "new york")
[1] 0.1206 0.0113 0.0084 0.0003 0.8594
predict_race("James", "Wong", NA, "new jersey")
[1] 0.4449 0.0373 0.0074 0.0002 0.5103


Backtest accuracy on census data 
```{r, include=F, eval=F}
rows <- sample(nrow(dat), 50)
temp <- dat[rows, c(3,4,4,5)]
temp[,3] <- NA
actual <- dat[rows, 'RACE']
# table(actual)
names(temp) <- c("first","last","spouse","state")
start <- proc.time()
race_prob_mat <- apply(temp, 1, function(row) do.call(predict_race, as.list(row)))
print(proc.time()-start)

pred <- apply(race_prob_mat[1:length(races),], 2, function(col) races[which.max(col)])
p <- mean(unlist(pred)==actual)
se <- sqrt(p*(1-p)/length(rows))
ci <- p+c(-1,1)*qnorm(.975)*se
cat(sprintf("95%% CI: [%.4f, %.4f]\n", ci[1], ci[2]))
```
Testing the algorithm using census data, we achieve an accuracy of around 90%.


train-test split (by state and overall)
```{r}
backtest <- function(nsim = 2000)
{
  output_mat <- matrix(NA, length(states)+1, 4)
  auc_mat <- matrix(NA, length(states)+1, length(races))
  start <- proc.time()
  for (i in 1:length(states))
  {
    dat_i <- dat[dat$STATEFIP == states[i],]
    rows <- sample(nrow(dat_i), nsim)
    temp <- dat_i[rows, c(3,4,4,5)]
    temp[,3] <- NA
    actual <- dat_i[rows, 'RACE']
    names(temp) <- c("first","last","spouse","state")
    temp$first <- ifelse(nchar(temp$first) == 1, NA, temp$first)
    race_prob_mat <- apply(temp, 1, function(row) do.call(predict_race, as.list(row)))
    
    for (r in 1:length(races))
    {
      labels <- ifelse(actual == races[r], 1, 0)
      if (all(labels == 0) | all(labels == 1))
      {
        auc_mat[i,r] <- NA
      }
      else
      {
        auc_mat[i,r] <- round(auc(roc(labels, t(race_prob_mat)[,r])),4)
      }
    }
    # print(auc_mat[i,])
    
    pred <- apply(race_prob_mat[1:length(races),], 2, function(col) races[which.max(col)])
    p <- mean(unlist(pred)==actual)
    se <- sqrt(p*(1-p)/nsim)
    ci <- p+c(-1,1)*qnorm(.975)*se
    output_mat[i,] <- round(c(ci[1], p, ci[2], nsim), 4)
  }
  
  # run overall
  rows <- sample(nrow(dat), 5*nsim)
  temp <- dat[rows, c(3,4,4,5)]
  temp[,3] <- NA
  actual <- dat[rows, 'RACE']
  names(temp) <- c("first","last","spouse","state")
  race_prob_mat <- apply(temp, 1, function(row) do.call(predict_race, as.list(row)))
  
  for (r in 1:length(races))
  {
    labels <- ifelse(actual == races[r], 1, 0)
    if (all(labels == 0) | all(labels == 1))
    {
      auc_mat[length(states)+1, r] <- NA
    }
    else
    {
      auc_mat[length(states)+1, r] <- round(auc(roc(labels, t(race_prob_mat)[,r])),4)
    }
  }
  
  pred <- apply(race_prob_mat[1:length(races),], 2, function(col) races[which.max(col)])
  p <- mean(unlist(pred)==actual)
  se <- sqrt(p*(1-p)/length(rows))
  ci <- p+c(-1,1)*qnorm(.975)*se
  output_mat[length(states)+1,] <- round(c(ci[1], p, ci[2], nsim*5), 4)
  print(proc.time()-start)
   
  result <- cbind(c(states, "overall"), auc_mat, output_mat)
  colnames(result) <- c('state', paste0("AUC(", races, ")"), 'lower', 'center', 'upper', "N")
  return(result)
}

```
```{r, warning=F}
result_1 <- backtest(nsim = 2500)
result_2 <- backtest(nsim = 2500)
result_3 <- backtest(nsim = 5000)

write.xlsx(list("backtest_1" = result_1,
                "backtest_2" = result_2,
                "backtest_3" = result_3),
           file = paste0(sub_path, "Table 7 - Backtest Accuracy.xlsx"))
```

Now, we will run the algorithm on the loan cards data.
```{r}
races <- unique(dat_new$RACE)
race_tab <- tapply(dat_new$N, dat_new$RACE, sum)[races]
dat_state <- dat_new[, .(N=sum(N)), by = .(STATEFIP, RACE)]
dat_region <- dat_new[, .(N=sum(N)), by = .(REGION, RACE)]
dat_last <- dat_new[dat_new$NAMELAST %in% unique(loan_card$last),]
dat_last <- dat_last[, .(N=sum(N)), by = .(NAMELAST, RACE)]
dat_frst <- dat_new[dat_new$NAMEFRST %in% unique(c(loan_card$first, loan_card$spouse)),]
dat_frst <- dat_frst[, .(N=sum(N)), by = .(NAMEFRST, RACE)]
ln_tab <- tapply(dat_last$N, dat_last$NAMELAST, sum)
fn_tab <- tapply(dat_frst$N, dat_frst$NAMEFRST, sum)
```
```{r}
# race_prob_list <- replicate(100,rep(NA,5),simplify=F)
names(loan_card)[names(loan_card)=="state_name"] <- "state"
# rows <- sample(nrow(loan_card), 100)
start <- proc.time()
race_prob_mat <- apply(loan_card, 1,
                        function(row) do.call(predict_race, as.list(row)))
# race_prob_mat <- pmap(loan_card[rows,], predict_race)
print(proc.time()-start)
# table(race_prob_mat[6,])
```
Note that the runtime of this for only 100 records already take around 5 seconds - this implies that just for Kate's loan cards, the algorithm needs to run for around 30 minutes. This means that we need to look for ways to improve its efficiency.

Example of predicted probabilities
```{r}
output <- cbind(loan_card, t(race_prob_mat), file_name)
names(output)[5:(5+length(races))] <- c(races, "step")
head(output, 10)
fwrite(output, paste0(sub_path, 'loan_card_predictions.csv'))
```
























Attempt to implement parallel-computing (unsuccessful)
```{r, eval=F}
start <- proc.time()
race_prob_mat <- replicate(100,rep(NA,5),simplify=F)
names(loan_card)[names(loan_card)=="state_name"] <- "state"
start <- proc.time()
cl <- makeCluster(2)
registerDoParallel(cl)
# race_prob_mat <- foreach(as.list(data.frame(t(loan_card[1:100,]))), .combine = c) %dopar% {
#   do.call(predict_race, row)
# }
race_prob_mat <- foreach(i=1:100) %dopar% do.call(predict_race, as.list(loan_card[i,]))
stopCluster(cl)
 # split(race_prob_mat, 1:length(race_prob_mat))
print(proc.time()-start)
```

Algorithm 2 (repeated relaxation)
1) if most John Doe living in NJ is white, then he is white
2) if most John Doe living in NJ is tied to be black and white, then we relax the state requirement and compare the amount of John Does in all states (repeat step 1)
    - if still tie, use spouse name, starting with step 1, then relax
    - if still tie, relax first name, and only use last name + state
    - if no spouse or still tie, randomly guess between tied categories
3) if no John Doe lives in NJ, repeat in the order of step 2; guess 'white' if reduced down to last name and state and still no existence

benefits compared to BISG (with F): 
1) more accurate for minority prediction
2) avoid no-matches (and less random guessing due to multiple relaxation steps)

- won't implement this for now; BISG is also able to capture this if we incorporate the relaxation logic into it


```{r, include=F}
dict_city <- read.csv("dict_city.csv")
dict_statefip <- read.csv("dict_state.csv")
```
```{r, include=F}
# sample loan cards data
# fn <- c('John C', 'James', 'Robert', 'Michael', 'William', 'David', 
#         'Richard', 'Thomas', 'Joseph', 'Daniel', 'Matthew', 'Anthony', 
#         'Steven', 'Paul', 'Kenneth', 'Malik', 'Jamal', 'Tyrone', 'Keisha', 
#         'Yuki', 'Mei', 'Juan', 'Miguel', 'Diego', 'Pedro', 'Alejandro', 'Jose')
# ln <- c('Smith', 'Johnson', 'Williams', 'Jones', 'Brown', 'Davis', 'Miller',
#         'Wilson', 'Martin', 'Anderson', 'Garcia', 'Lopez', 'Gomez', 'Torres',
#         'Jackson', 'Chen', 'Lee', 'Patel', 'Liu', 'Nguyen', 'Lewis', 'Adams',
#         'White', 'Robinson', 'Taylor', 'Gonzalez', 'Sato', 'Jordan')
# 
# n <- 5
# fn <- sample(fn, n, replace = T)
# ln <- sample(ln, n, replace = T)
# fn <- sub("^(\\w+)\\s.*", "\\1", fn)
# city <- sample(dict_city$label, n, replace = T)
# state <- sample(dict_statefip$label, n, replace = T)
# 
# loan_card <- data.frame('NAMEFRST' = fn, 
#                         'NAMELAST' = ln,
#                         'STATEFIP' = state)
# head(loan_card)
```




